{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting Started with Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "\n",
    "YouTubeVideo('mPFq5KMxKVw', width=800, height=450)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginner's intro to Malaria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Malaria_cycle](https://i1.wp.com/www.malariasite.com/wp-content/uploads/2015/02/EID_lec17_slide8-large.jpg?resize=799%2C664&ssl=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "YouTubeVideo('3_2TnCqBFcY', width=800, height=450)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Prerequisite Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.applications import MobileNetV2, VGG19\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras import regularizers\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, InputLayer, Reshape, Conv1D, MaxPool1D, SeparableConv2D\n",
    "import time\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Parasitized', 'Uninfected']\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "print(os.listdir(\"input/cell_images/cell_images/\"))\n",
    "\n",
    "base_dir = 'input/cell_images/cell_images/'\n",
    "work_dir = 'work/'\n",
    "#os.mkdir(work_dir)\n",
    "\n",
    "base_dir_A = 'input/cell_images/cell_images/Parasitized/' \n",
    "base_dir_B = 'input/cell_images/cell_images/Uninfected/'\n",
    "\n",
    "work_dir_A = 'work/A/'\n",
    "#os.mkdir(work_dir_A)\n",
    "work_dir_B = 'work/B/'\n",
    "#os.mkdir(work_dir_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New directories for train, validation, and test created\n",
      "Train, Validation, and Test folders made for both A and B datasets\n"
     ]
    }
   ],
   "source": [
    "train_dir = os.path.join(work_dir, 'train')\n",
    "#os.mkdir(train_dir)\n",
    "\n",
    "validation_dir = os.path.join(work_dir, 'validation')\n",
    "#os.mkdir(validation_dir)\n",
    "\n",
    "test_dir = os.path.join(work_dir, 'test')\n",
    "#os.mkdir(test_dir)\n",
    "\n",
    "print(\"New directories for train, validation, and test created\")\n",
    "train_pos_dir = os.path.join(train_dir, 'pos')\n",
    "#os.mkdir(train_pos_dir)\n",
    "train_neg_dir = os.path.join(train_dir, 'neg')\n",
    "#os.mkdir(train_neg_dir)\n",
    "\n",
    "validation_pos_dir = os.path.join(validation_dir, 'pos')\n",
    "#os.mkdir(validation_pos_dir)\n",
    "validation_neg_dir = os.path.join(validation_dir, 'neg')\n",
    "#os.mkdir(validation_neg_dir)\n",
    "\n",
    "test_pos_dir = os.path.join(test_dir, 'pos')\n",
    "#os.mkdir(test_pos_dir)\n",
    "test_neg_dir = os.path.join(test_dir, 'neg')\n",
    "#os.mkdir(test_neg_dir)\n",
    "\n",
    "print(\"Train, Validation, and Test folders made for both A and B datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 10\u001b[0m\n\u001b[0;32m      6\u001b[0m     dst \u001b[38;5;241m=\u001b[39mwork_dir_A \u001b[38;5;241m+\u001b[39m dst \n\u001b[0;32m      8\u001b[0m        \u001b[38;5;66;03m# rename() function will \u001b[39;00m\n\u001b[0;32m      9\u001b[0m        \u001b[38;5;66;03m# rename all the files \u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m     \u001b[43mshutil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m     11\u001b[0m     i \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     14\u001b[0m j \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\bryan\\anaconda3\\envs\\PROJMAST1\\Lib\\shutil.py:428\u001b[0m, in \u001b[0;36mcopy\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[0;32m    427\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[1;32m--> 428\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    429\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[0;32m    430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[1;32mc:\\Users\\bryan\\anaconda3\\envs\\PROJMAST1\\Lib\\shutil.py:260\u001b[0m, in \u001b[0;36mcopyfile\u001b[1;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[0;32m    258\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 260\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[0;32m    261\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    262\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[0;32m    263\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "      \n",
    "for filename in os.listdir(base_dir_A): \n",
    "    dst =\"pos\" + str(i) + \".jpg\"\n",
    "    src =base_dir_A + filename \n",
    "    dst =work_dir_A + dst \n",
    "          \n",
    "       # rename() function will \n",
    "       # rename all the files \n",
    "    shutil.copy(src, dst) \n",
    "    i += 1\n",
    "\n",
    "\n",
    "j = 0\n",
    "\n",
    "for filename in os.listdir(base_dir_B): \n",
    "    dst =\"neg\" + str(j) + \".jpg\"\n",
    "    src =base_dir_B + filename \n",
    "    dst =work_dir_B + dst \n",
    "          \n",
    "    # rename() function will \n",
    "    # rename all the files \n",
    "    shutil.copy(src, dst) \n",
    "    j += 1       \n",
    "        \n",
    "print(\"Images for both categories have been copied to working directories, renamed to A & B + num\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parasitized Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "fnames = ['pos{}.jpg'.format(i) for i in range(3000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_A, fname)\n",
    "    dst = os.path.join(train_pos_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['pos{}.jpg'.format(i) for i in range(3000, 4000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_A, fname)\n",
    "    dst = os.path.join(validation_pos_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['pos{}.jpg'.format(i) for i in range(4000, 4500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_A, fname)\n",
    "    dst = os.path.join(test_pos_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uninfected Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "fnames = ['neg{}.jpg'.format(i) for i in range(3000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_B, fname)\n",
    "    dst = os.path.join(train_neg_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['neg{}.jpg'.format(i) for i in range(3000, 4000)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_B, fname)\n",
    "    dst = os.path.join(validation_neg_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "\n",
    "fnames = ['neg{}.jpg'.format(i) for i in range(4000, 4500)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(work_dir_B, fname)\n",
    "    dst = os.path.join(test_neg_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "print(\"Train, validation, and test datasets split and ready for use\")\n",
    "print('total training pos images:', len(os.listdir(train_pos_dir)))\n",
    "print('total training neg images:', len(os.listdir(train_neg_dir)))\n",
    "print('total validation pos images:', len(os.listdir(validation_pos_dir)))\n",
    "print('total validation neg images:', len(os.listdir(validation_neg_dir)))\n",
    "print('total test pos images:', len(os.listdir(test_pos_dir)))\n",
    "print('total test neg images:', len(os.listdir(test_neg_dir)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1.0/255.0, validation_split=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow_from_directory(directory= train_dir,             \n",
    "                                                     target_size=(128, 128),\n",
    "                                                     class_mode='binary',\n",
    "                                                     subset='training',\n",
    "                                                    shuffle=True,\n",
    "                                                     batch_size=32\n",
    "                                 )\n",
    "\n",
    "valid_generator = train_datagen.flow_from_directory(directory= validation_dir,\n",
    "                                                      target_size=(128, 128),\n",
    "                                                     class_mode='binary',\n",
    "                                                           shuffle = True,\n",
    "                                                     subset='validation',\n",
    "                                                     batch_size=32,\n",
    "                                                    \n",
    "                                                     )\n",
    "\n",
    "\n",
    "classes = ['Parasitized', 'Uninfected']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Displaying The Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "sample_training_images, train_label = next(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def plotImages(images_arr):\n",
    "    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n",
    "    axes = axes.flatten()\n",
    "    for img, ax in zip(images_arr, axes):\n",
    "        ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    plt.tight_layout() \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('Random Display of Cell images')\n",
    "plotImages(sample_training_images[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Depth-Wise Separable CNN (DS-CNN)\n",
    "\n",
    "This model is faster form of convolution model \n",
    "You can understand more about this [here](https://www.youtube.com/watch?vT7o3xvJLuHk&t=12s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "input_length = 128,128,3\n",
    "\n",
    "ds_model = Sequential()\n",
    "ds_model.add(Conv2D(16,(3,3),activation='relu',input_shape=(128,128,3)))\n",
    "ds_model.add(MaxPool2D(2,2))\n",
    "ds_model.add(Dropout(0.2))\n",
    "\n",
    "ds_model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "ds_model.add(MaxPool2D(2,2))\n",
    "ds_model.add(Dropout(0.2))\n",
    "\n",
    "ds_model.add(SeparableConv2D(64,(3,3),activation='relu'))\n",
    "ds_model.add(MaxPool2D(2,2))\n",
    "ds_model.add(Dropout(0.3))\n",
    "\n",
    "ds_model.add(SeparableConv2D(128,(3,3),activation='relu'))\n",
    "ds_model.add(MaxPool2D(2,2))\n",
    "ds_model.add(Dropout(0.3))\n",
    "\n",
    "ds_model.add(Flatten())\n",
    "ds_model.add(Dense(64,activation='relu'))\n",
    "ds_model.add(Dropout(0.5))\n",
    "\n",
    "ds_model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "ds_model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "ds_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = ds_model.fit_generator(train_generator,\n",
    "                              epochs=20,\n",
    "                              steps_per_epoch= len(train_generator),\n",
    "                              validation_data = (valid_generator),\n",
    "                              callbacks = [early_stop]\n",
    "                              #verbose=1\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metrics Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_training(history, lw = 3):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Accuracy vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "visualize_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "ds_model_name = 'dsmalaria_predsmodel.h5'\n",
    "ds_model.save_weights(ds_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet Model Developement\n",
    "\n",
    "***Here I will be using MobileNetV2 architecture below I will be showing architecture of different MobileNet models***\n",
    "\n",
    "![mobilenet](https://miro.medium.com/max/1882/1*bqE59FvgpvoAQUMQ0WEoUA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(MobileNetV2(include_top=False, pooling='avg', weights='imagenet', input_shape=(128, 128, 3), classes=2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\n",
    "model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=20,\n",
    "                              steps_per_epoch= len(train_generator),\n",
    "                              validation_data = (valid_generator),\n",
    "                              callbacks = [early_stop],\n",
    "                              verbose=1\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model metrics plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_training(history, lw = 3):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Accuracy vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "visualize_training(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "model_name = 'malaria_predsmodel.h5'\n",
    "model.save_weights(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-19\n",
    "\n",
    "![vgg_architecture](https://www.researchgate.net/profile/Clifford_Yang/publication/325137356/figure/fig2/AS:670371271413777@1536840374533/llustration-of-the-network-architecture-of-VGG-19-model-conv-means-convolution-FC-means.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vgg_model = Sequential()\n",
    "vgg_model.add(VGG19(include_top=False, pooling='avg', weights='imagenet', input_shape=(128, 128, 3), classes=2))\n",
    "vgg_model.add(Flatten())\n",
    "vgg_model.add(Dense(256,activation='relu'))\n",
    "vgg_model.add(Dense(64,activation='relu'))\n",
    "vgg_model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "vgg_model.layers[0].trainable = False\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999)\n",
    "vgg_model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vgg_history = vgg_model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = len(train_generator),\n",
    "                              epochs=20,\n",
    "                              validation_steps = len(valid_generator),\n",
    "                                      validation_data = valid_generator,\n",
    "                              callbacks = [early_stop],\n",
    "                                      verbose=1\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save VGG model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "vgg_model_name = 'vgg_malaria_predsmodel.h5'\n",
    "model.save_weights(vgg_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_training(vgg_history, lw = 3):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(vgg_history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(vgg_history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Accuracy vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(vgg_history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(vgg_history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "visualize_training(vgg_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3\n",
    "\n",
    "![architecture](https://miro.medium.com/max/960/1*gqKM5V-uo2sMFFPDS84yJw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inception_model = Sequential()\n",
    "inception_model.add(tf.keras.applications.InceptionV3(include_top=False, pooling='avg', weights='imagenet', input_shape=(128, 128, 3), classes=2))\n",
    "inception_model.add(Flatten())\n",
    "inception_model.add(Dense(64,activation='relu'))\n",
    "inception_model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "inception_model.layers[0].trainable = False\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(lr=0.00005, beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "inception_model.compile(optimizer= opt, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "inception_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inception_history = inception_model.fit_generator(train_generator,\n",
    "                              steps_per_epoch = len(train_generator),\n",
    "                              epochs=20,\n",
    "                              validation_data=valid_generator,\n",
    "                              callbacks = [early_stop],\n",
    "                                                  verbose=1\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "inception_model_name = 'inceptionv3_malaria_predsmodel.h5'\n",
    "model.save_weights(inception_model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionV3 metrics plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def visualize_training(inception_history, lw = 3):\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(inception_history.history['accuracy'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(inception_history.history['val_accuracy'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Accuracy vs Validation Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.plot(inception_history.history['loss'], label = 'training', marker = '*', linewidth = lw)\n",
    "    plt.plot(inception_history.history['val_loss'], label = 'validation', marker = 'o', linewidth = lw)\n",
    "    plt.title('Training Loss vs Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(fontsize = 'x-large')\n",
    "    plt.show()\n",
    "visualize_training(inception_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking Trained Data on Test Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_datagen = ImageDataGenerator(rescale=1./255)\n",
    "eval_generator = eval_datagen.flow_from_directory(\n",
    "        test_dir,target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "eval_generator.reset()    \n",
    "pred = ds_model.predict_generator(eval_generator,1000,verbose=1)\n",
    "print(\"Predictions finished\")\n",
    "  \n",
    "import matplotlib.image as mpimg\n",
    "for index, probability in enumerate(pred):\n",
    "    image_path = test_dir + \"/\" +eval_generator.filenames[index]\n",
    "    img = mpimg.imread(image_path)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    print(eval_generator.filenames[index])\n",
    "    if probability > 0.5:\n",
    "        plt.title(\"%.2f\" % (probability[0]*100) + \"% B\")\n",
    "    else:\n",
    "        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% A\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_datagen = ImageDataGenerator(rescale=1./255)\n",
    "eval_generator = eval_datagen.flow_from_directory(\n",
    "        test_dir,target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "eval_generator.reset()    \n",
    "pred = model.predict_generator(eval_generator,1000,verbose=1)\n",
    "print(\"Predictions finished\")\n",
    "  \n",
    "import matplotlib.image as mpimg\n",
    "for index, probability in enumerate(pred):\n",
    "    image_path = test_dir + \"/\" +eval_generator.filenames[index]\n",
    "    img = mpimg.imread(image_path)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    print(eval_generator.filenames[index])\n",
    "    if probability > 0.5:\n",
    "        plt.title(\"%.2f\" % (probability[0]*100) + \"% B\")\n",
    "    else:\n",
    "        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% A\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_datagen = ImageDataGenerator(rescale=1./255)\n",
    "eval_generator = eval_datagen.flow_from_directory(\n",
    "        test_dir,target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "eval_generator.reset()    \n",
    "pred = vgg_model.predict_generator(eval_generator,1000,verbose=1)\n",
    "print(\"Predictions finished\")\n",
    "  \n",
    "import matplotlib.image as mpimg\n",
    "for index, probability in enumerate(pred):\n",
    "    image_path = test_dir + \"/\" +eval_generator.filenames[index]\n",
    "    img = mpimg.imread(image_path)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    print(eval_generator.filenames[index])\n",
    "    if probability > 0.5:\n",
    "        plt.title(\"%.2f\" % (probability[0]*100) + \"% B\")\n",
    "    else:\n",
    "        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% A\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# InceptionNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_datagen = ImageDataGenerator(rescale=1./255)\n",
    "eval_generator = eval_datagen.flow_from_directory(\n",
    "        test_dir,target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        class_mode='binary')\n",
    "eval_generator.reset()    \n",
    "pred = inception_model.predict_generator(eval_generator,1000,verbose=1)\n",
    "print(\"Predictions finished\")\n",
    "  \n",
    "import matplotlib.image as mpimg\n",
    "for index, probability in enumerate(pred):\n",
    "    image_path = test_dir + \"/\" +eval_generator.filenames[index]\n",
    "    img = mpimg.imread(image_path)\n",
    "    \n",
    "    plt.imshow(img)\n",
    "    print(eval_generator.filenames[index])\n",
    "    if probability > 0.5:\n",
    "        plt.title(\"%.2f\" % (probability[0]*100) + \"% B\")\n",
    "    else:\n",
    "        plt.title(\"%.2f\" % ((1-probability[0])*100) + \"% A\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Big thanks to Medium article of Adrian Yijie Xu for excellent [article](https://medium.com/gradientcrescent/building-a-malaria-classifier-with-keras-background-implementation-d55c32773afa), \n",
    "Do check it out!!***\n",
    " ***"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 87153,
     "sourceId": 200743,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 29962,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "PROJMAST1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
