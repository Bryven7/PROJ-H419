{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "37aae2f387f795896f3502e83625538d6223dfa2"
   },
   "source": [
    "<center><h1>Detecting Malaria cells using Convolutional Neural Network</h1></center>\n",
    "![ml](https://www.h-its.org/wp-content/uploads/2018/07/Malaria_Press_image_1.png)    \n",
    "    \n",
    "   ### Steps to solve the problem :- \n",
    "   1. Importing Libraries.\n",
    "   2. Loading the data.\n",
    "   3. Data preprocessing.\n",
    "   4. Data augmentation.\n",
    "   5. Ploting images and its labels to understand how does an infected cell and uninfected cell looks like.\n",
    "   6. Spliting data in Train , Evaluation and Test set.\n",
    "   7. Creating a Convolution Neural Network function.\n",
    "   8. Wrapping it with Tensorflow Estimator function.\n",
    "   9. Training the data on Train data.\n",
    "   10. Evaluating on evaluation data.\n",
    "   11. Predicting on Test data\n",
    "   12. Ploting the predicted image and its respective True value and predicted value.\n",
    "   \n",
    "   ### Note :\n",
    "*   This is my second image classification task.\n",
    "*    Please feel free to suggest me what should i have done more to improve the model to perform more better.\n",
    "*    Please upvote this kernel if you liked my work , Thank you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\bryan\\OneDrive - Université Libre de Bruxelles\\Master 1 Ingénieur Civile\\PROJ-H419 - Biomedical engineering project in image analysis - 202526\\PROJ-H419\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cell_images', 'Parasitized', 'Uninfected']\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import Dense, Dropout, Flatten, Conv2D\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "import albumentations as A\n",
    "import os\n",
    "print(os.listdir(\"input/cell_images\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "infected = os.listdir('input/cell_images/cell_images/Parasitized/') \n",
    "uninfected = os.listdir('input/cell_images/cell_images/Uninfected/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "6c62996edd0483c29a8e5a8b8ec5b772bb5a0f11",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "data_path = []\n",
    "labels = []\n",
    "\n",
    "for i in infected:\n",
    "    try:\n",
    "        data_path.append(\"input/cell_images/cell_images/Parasitized/\"+i)\n",
    "        labels.append(1) \n",
    "    except AttributeError:\n",
    "        raise ValueError('Error processing infected image path')\n",
    "    \n",
    "for u in uninfected:\n",
    "    try:\n",
    "        data_path.append(\"input/cell_images/cell_images/Uninfected/\"+u)\n",
    "        labels.append(0)\n",
    "    except AttributeError:\n",
    "        raise ValueError('Error processing uninfected image path')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "5234f0d7d29b7ea0adc022a9964590b0610032f3",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cells_path = np.array(data_path)\n",
    "labels = np.array(labels)\n",
    "\n",
    "np.save('Cells' , cells_path)\n",
    "np.save('Labels' , labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "53020513151df530a51081741617687a8a789b30",
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cells : (0,) | labels : (0,)\n"
     ]
    }
   ],
   "source": [
    "print('Cells : {} | labels : {}'.format(cells_path.shape , labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e4580e19f93d4427d7a7f88e739c1ef77d216847",
    "trusted": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "high <= 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m49\u001b[39m):\n\u001b[0;32m      4\u001b[0m     n \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \n\u001b[1;32m----> 5\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandint\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcells\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      6\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m7\u001b[39m , \u001b[38;5;241m7\u001b[39m , n)\n\u001b[0;32m      7\u001b[0m     plt\u001b[38;5;241m.\u001b[39msubplots_adjust(hspace \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m , wspace \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m)\n",
      "File \u001b[1;32mnumpy/random/mtrand.pyx:794\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.randint\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mnumpy/random/_bounded_integers.pyx:2885\u001b[0m, in \u001b[0;36mnumpy.random._bounded_integers._rand_int32\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: high <= 0"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x900 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1 , figsize = (15 , 9))\n",
    "n = 0 \n",
    "for i in range(49):\n",
    "    n += 1 \n",
    "    r = np.random.randint(0 , cells.shape[0] , 1)\n",
    "    plt.subplot(7 , 7 , n)\n",
    "    plt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n",
    "    plt.imshow(cells[r[0]])\n",
    "    plt.title('{} : {}'.format('Infected' if labels[r[0]] == 1 else 'Unifected' ,\n",
    "                               labels[r[0]]) )\n",
    "    plt.xticks([]) , plt.yticks([])\n",
    "    \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c3d17aa73556bb631c0f51043da62e0e74f7f2f",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1, figsize = (15 , 7))\n",
    "plt.subplot(1 , 2 , 1)\n",
    "plt.imshow(cells[0])\n",
    "plt.title('Infected Cell')\n",
    "plt.xticks([]) , plt.yticks([])\n",
    "\n",
    "plt.subplot(1 , 2 , 2)\n",
    "plt.imshow(cells[60000])\n",
    "plt.title('Uninfected Cell')\n",
    "plt.xticks([]) , plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2c607eb7ac48a824e67cb3d9c0029c04712b8087",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "n = np.arange(cells.shape[0])\n",
    "np.random.shuffle(n)\n",
    "cells = cells[n]\n",
    "labels = labels[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ffa4c1094d41db8ec76f69d3cd547bc7e355b193",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cells = cells.astype(np.float32)\n",
    "labels = labels.astype(np.int32)\n",
    "cells = cells/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "251dcd279dbb17e3b53133843226e911727d5d1e",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x , x , train_y , y = train_test_split(cells , labels , \n",
    "                                            test_size = 0.2 ,\n",
    "                                            random_state = 111)\n",
    "\n",
    "eval_x , test_x , eval_y , test_y = train_test_split(x , y , \n",
    "                                                    test_size = 0.5 , \n",
    "                                                    random_state = 111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ca209c38627bb47450632dd707aab107f82de104",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1 , figsize = (15 ,5))\n",
    "n = 0 \n",
    "for z , j in zip([train_y , eval_y , test_y] , ['train labels','eval labels','test labels']):\n",
    "    n += 1\n",
    "    plt.subplot(1 , 3  , n)\n",
    "    sns.countplot(x = z )\n",
    "    plt.title(j)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b1406e372de9104f5ba7c9e5f318073c37670db2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print('train data shape {} ,eval data shape {} , test data shape {}'.format(train_x.shape,\n",
    "                                                                           eval_x.shape ,\n",
    "                                                                           test_x.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "176aba5ea61ebf8d1ef170401c07b22f19f620a6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "def cnn_model_fn(features , labels , mode):\n",
    "    input_layers = tf.reshape(features['x'] , [-1 , 50 , 50 ,3])    \n",
    "    conv1 = tf.layers.conv2d(\n",
    "        inputs = input_layers , \n",
    "        filters = 50 , \n",
    "        kernel_size = [7 , 7],\n",
    "        padding = 'same',\n",
    "        activation = tf.nn.relu\n",
    "        ) \n",
    "    \n",
    "    \n",
    "    conv2 = tf.layers.conv2d(\n",
    "        inputs = conv1, \n",
    "        filters = 90,\n",
    "        kernel_size = [3 , 3],\n",
    "        padding = 'valid',\n",
    "        activation = tf.nn.relu\n",
    "        )\n",
    "\n",
    "        \n",
    "    conv3 = tf.layers.conv2d(\n",
    "        inputs = conv2 ,\n",
    "        filters = 10,\n",
    "        kernel_size = [5 , 5],\n",
    "        padding = 'same', \n",
    "        activation = tf.nn.relu\n",
    "        )\n",
    "    \n",
    "    pool1 = tf.layers.max_pooling2d(inputs = conv3 , pool_size = [2 , 2] ,\n",
    "                                    strides = 2 )\n",
    "    conv4 = tf.layers.conv2d(\n",
    "        inputs = pool1 ,\n",
    "        filters = 5,\n",
    "        kernel_size = [3 , 3],\n",
    "        padding = 'same', \n",
    "        activation = tf.nn.relu\n",
    "        )\n",
    "\n",
    "    pool2 = tf.layers.max_pooling2d(inputs = conv4 , pool_size = [2 , 2] ,\n",
    "                                    strides = 2 , padding = 'same')\n",
    "    \n",
    "    pool2_flatten = tf.layers.flatten(pool2)\n",
    "    fc1 = tf.layers.dense(\n",
    "        inputs = pool2_flatten,\n",
    "        units = 2000,\n",
    "        activation = tf.nn.relu\n",
    "        )\n",
    "    fc2 = tf.layers.dense(\n",
    "        inputs = fc1,\n",
    "        units = 1000,\n",
    "        activation = tf.nn.relu\n",
    "        )\n",
    "    fc3 = tf.layers.dense(\n",
    "        inputs = fc2 , \n",
    "        units = 500 ,\n",
    "        activation = tf.nn.relu\n",
    "        )\n",
    "    logits = tf.layers.dense(\n",
    "        inputs = fc3 ,\n",
    "        units = 2\n",
    "        )\n",
    "    \n",
    "    predictions = {\n",
    "        'classes': tf.argmax(input = logits , axis = 1),\n",
    "        'probabilities': tf.nn.softmax(logits , name = 'softmax_tensor')\n",
    "    }\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        return tf.estimator.EstimatorSpec(mode = mode , \n",
    "                                          predictions = predictions)\n",
    "    \n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels = labels , \n",
    "                                                 logits = logits)\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.GradientDescentOptimizer(learning_rate = 0.001)\n",
    "        train_op = optimizer.minimize(loss = loss , \n",
    "                                      global_step = tf.train.get_global_step())\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode = mode , \n",
    "                                            loss = loss , \n",
    "                                            train_op = train_op \n",
    "                                           )\n",
    "    eval_metric_op = {'accuracy' : tf.metrics.accuracy(labels = labels ,\n",
    "                                         predictions =  predictions['classes'])}\n",
    "    \n",
    "    return tf.estimator.EstimatorSpec(mode = mode , \n",
    "                                      loss = loss , \n",
    "                                      eval_metric_ops = eval_metric_op)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fe31b7a2946fd74ebd6e6ffc18585fa74e6e47e6",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "malaria_detector = tf.estimator.Estimator(model_fn = cnn_model_fn , \n",
    "                                         model_dir = '/tmp/modelchkpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1c18c3afc63c767d095fda7064ec677e30010563",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "tensors_to_log = {'probabilities':'softmax_tensor'}\n",
    "logging_hook = tf.train.LoggingTensorHook(\n",
    "    tensors = tensors_to_log , every_n_iter = 50 \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-output": true,
    "_uuid": "310c9c6e0a2920718c5d732ad74effcdc6e09f3a",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {'x': train_x},\n",
    "    y = train_y,\n",
    "    batch_size = 100 , \n",
    "    num_epochs = None , \n",
    "    shuffle = True\n",
    "    )\n",
    "malaria_detector.train(input_fn = train_input_fn , steps = 1 , hooks = [logging_hook])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "170414463295476d4428dc4a2d89168b0915963e",
    "scrolled": true,
    "trusted": true
   },
   "outputs": [],
   "source": [
    "malaria_detector.train(input_fn = train_input_fn , steps = 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "06c4f121e1c6b9a3a25800cb1d88a1ae0a3428b4",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {'x': eval_x},\n",
    "    y = eval_y , \n",
    "    num_epochs = 1 , \n",
    "    shuffle = False\n",
    "    )\n",
    "eval_results = malaria_detector.evaluate(input_fn = eval_input_fn)\n",
    "print(eval_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a36281e539716be25f596594c34e7c2a04783de2",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "pred_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x = {'x' : test_x},\n",
    "    y = test_y,\n",
    "    num_epochs = 1,\n",
    "    shuffle = False\n",
    "    )\n",
    "\n",
    "y_pred = malaria_detector.predict(input_fn = pred_input_fn)\n",
    "classes = [p['classes'] for p in y_pred]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "76efc74c3f013168ea4fdadc8fc2e9f5f3b5f465",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix , classification_report , accuracy_score\n",
    "print('{} \\n{} \\n{}'.format(confusion_matrix(test_y , classes) , \n",
    "                           classification_report(test_y , classes) , \n",
    "                           accuracy_score(test_y , classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4a0942e25e79957c5932013fa55d51f7282dd87b",
    "trusted": true
   },
   "outputs": [],
   "source": [
    "plt.figure(1 , figsize = (15 , 9))\n",
    "n = 0 \n",
    "for i in range(49):\n",
    "    n += 1 \n",
    "    r = np.random.randint( 0  , test_x.shape[0] , 1)\n",
    "    plt.subplot(7 , 7 , n)\n",
    "    plt.subplots_adjust(hspace = 0.5 , wspace = 0.5)\n",
    "    plt.imshow(test_x[r[0]])\n",
    "    plt.title('true {} : pred {}'.format(test_y[r[0]] , classes[r[0]]) )\n",
    "    plt.xticks([]) , plt.yticks([])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 87153,
     "sourceId": 200743,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 20477,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "PROJMAST1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
